{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9605e2ab-8c7d-4cba-a775-2727674486f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def combine_unique_sentences(begin_range):\n",
    "\n",
    "    number_of_words_per_file = 100\n",
    "    end_range = begin_range + number_of_words_per_file\n",
    "    OUTPUT_FILE = f\"data/data_{begin_range}_{end_range-1}_all.json\" # using json format for better structure\n",
    "    \n",
    "    # Load data from json files\n",
    "    with open(f\"output/data_{begin_range}_{end_range-1}.json\", 'r', encoding='utf-8') as file1:\n",
    "        data_1 = json.load(file1)\n",
    "    \n",
    "    with open(f\"output/data_{begin_range}_{end_range-1}_1.json\", 'r', encoding='utf-8') as file2:\n",
    "        data_2 = json.load(file2)\n",
    "    \n",
    "    # Prepare the new data list\n",
    "    combined_data = []\n",
    "    \n",
    "    # Iterate through both data list and combine the relevant information\n",
    "    for i in range(100): # both file has the same 100 items\n",
    "        item_1 = data_1[i]\n",
    "        item_2 = data_2[i]\n",
    "    \n",
    "        # Combine the sentences from both files\n",
    "        combined_sentences = item_1['generated_sentences'][:-1] + item_2['generated_sentences'] #[:-1] remove the last sentence from data_0_99.json because this sentence is incomplete.\n",
    "        \n",
    "        # Remove duplicates by keeping only the first occurance of each sentence\n",
    "        unique_sentences = []\n",
    "        seen_sentences = set()\n",
    "        for sentence in combined_sentences:\n",
    "            if sentence not in seen_sentences:\n",
    "                unique_sentences.append(sentence)\n",
    "                seen_sentences.add(sentence)\n",
    "    \n",
    "        # Create a new item with combined data\n",
    "        combined_item = {\n",
    "            'word': item_1['word'],\n",
    "            'pos': item_1['pos'],\n",
    "            'definition': item_1['definition'],\n",
    "            'prompt': item_1['prompt'],\n",
    "            'generated_sentences': unique_sentences\n",
    "        }\n",
    "    \n",
    "        # Add the combined data item to the list\n",
    "        combined_data.append(combined_item)\n",
    "    \n",
    "    # Save the combined data into a new JSON file\n",
    "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(combined_data, outfile, ensure_ascii=False, indent=4)\n",
    "    \n",
    "    print(f\"Data combined successfully! Saved to file: {OUTPUT_FILE}\")\n",
    "    print(f\"Duplicated sentences found: {len(seen_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af6a1444-46af-41bd-9a47-652c0028a09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data combined successfully! Saved to file: data/data_0_99_all.json\n",
      "Duplicated sentences found: 71\n",
      "Data combined successfully! Saved to file: data/data_100_199_all.json\n",
      "Duplicated sentences found: 31\n",
      "Data combined successfully! Saved to file: data/data_200_299_all.json\n",
      "Duplicated sentences found: 72\n",
      "Data combined successfully! Saved to file: data/data_300_399_all.json\n",
      "Duplicated sentences found: 80\n",
      "Data combined successfully! Saved to file: data/data_400_499_all.json\n",
      "Duplicated sentences found: 61\n",
      "Data combined successfully! Saved to file: data/data_500_599_all.json\n",
      "Duplicated sentences found: 65\n",
      "Data combined successfully! Saved to file: data/data_600_699_all.json\n",
      "Duplicated sentences found: 69\n",
      "Data combined successfully! Saved to file: data/data_700_799_all.json\n",
      "Duplicated sentences found: 69\n",
      "Data combined successfully! Saved to file: data/data_800_899_all.json\n",
      "Duplicated sentences found: 95\n",
      "Data combined successfully! Saved to file: data/data_900_999_all.json\n",
      "Duplicated sentences found: 72\n"
     ]
    }
   ],
   "source": [
    "# begin_range = 0 # the index to start your dictionary loop\n",
    "for i in range(0,10):\n",
    "    begin_range = i*100\n",
    "    combine_sentences = combine_unique_sentences(begin_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a22b22c-df5c-4a0d-b785-ff8ab54b0e94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_lab",
   "language": "python",
   "name": "my_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
